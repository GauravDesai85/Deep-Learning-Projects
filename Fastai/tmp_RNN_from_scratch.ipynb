{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data read and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600893"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=open(f'{PATH}nietzsche.txt').read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrib'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0,'\\0')\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi={c:i for i,c in enumerate(chars)}\n",
    "itos={i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600893"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=[stoi[char] for char in text]\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic RNN model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fac=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "1 0 1\n",
      "2 0 2\n",
      "0 1 1\n",
      "1 1 2\n",
      "2 1 3\n",
      "0 2 2\n",
      "1 2 3\n",
      "2 2 4\n",
      "0 3 3\n",
      "1 3 4\n",
      "2 3 5\n",
      "0 4 4\n",
      "1 4 5\n",
      "2 4 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[None, None, None],\n",
       " [None, None, None],\n",
       " [None, None, None],\n",
       " [None, None, None],\n",
       " [None, None, None]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(cs)\n",
    "range(len(idx)-cs)\n",
    "\n",
    "[[print(i,j,i+j) for i in range(3)] for j in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat=[[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat=[idx[j+cs] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600885, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs=np.stack(c_in_dat,axis=0)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 42, 29, 30, 25, 27, 29,  1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.stack(c_out_dat,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx=get_cv_idxs(len(idx)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "md=ColumnarModelData.from_arrays('.',val_idx,xs,y,bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac):\n",
    "        super().__init__()\n",
    "        self.e=nn.Embedding(vocab_size,n_fac)\n",
    "        self.l_in=nn.Linear(n_fac,n_hidden)\n",
    "        self.l_hidden=nn.Linear(n_hidden,n_hidden)\n",
    "        self.l_out=nn.Linear(n_hidden,vocab_size)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "        bs=cs[0].size(0)\n",
    "        h=V(torch.zeros(bs,n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp=F.relu(self.l_in(self.e(c)))\n",
    "            h=F.tanh(self.l_hidden(h+inp))\n",
    "        return(F.log_softmax(self.l_out(h),dim=-1))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=FirstRNN(vocab_size,n_fac).cuda()\n",
    "opt=optim.Adam(m.parameters(),1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 56\n",
       " 68\n",
       "  2\n",
       " 56\n",
       " 65\n",
       " 58\n",
       " 68\n",
       " 74\n",
       " 62\n",
       " 57\n",
       " 73\n",
       " 62\n",
       " 69\n",
       " 60\n",
       " 69\n",
       " 59\n",
       " 73\n",
       " 72\n",
       " 71\n",
       " 68\n",
       " 72\n",
       " 54\n",
       " 65\n",
       " 68\n",
       "  2\n",
       " 29\n",
       " 62\n",
       " 62\n",
       " 74\n",
       " 67\n",
       " 68\n",
       " 72\n",
       " 65\n",
       " 69\n",
       "  2\n",
       " 61\n",
       " 71\n",
       " 78\n",
       " 73\n",
       "  2\n",
       " 54\n",
       " 54\n",
       "  2\n",
       " 71\n",
       " 58\n",
       " 72\n",
       " 55\n",
       " 73\n",
       " 54\n",
       " 73\n",
       " 59\n",
       " 62\n",
       " 58\n",
       " 72\n",
       "  2\n",
       "  9\n",
       " 71\n",
       " 58\n",
       " 67\n",
       " 78\n",
       " 65\n",
       " 65\n",
       " 72\n",
       " 73\n",
       " 65\n",
       " 67\n",
       "  2\n",
       " 61\n",
       " 73\n",
       " 67\n",
       " 65\n",
       " 67\n",
       " 58\n",
       " 67\n",
       " 72\n",
       " 33\n",
       " 39\n",
       " 31\n",
       " 69\n",
       " 54\n",
       "  2\n",
       " 67\n",
       "  2\n",
       " 57\n",
       "  2\n",
       " 67\n",
       "  1\n",
       " 66\n",
       "  2\n",
       "  2\n",
       " 65\n",
       " 61\n",
       " 71\n",
       " 56\n",
       " 62\n",
       " 73\n",
       " 73\n",
       "  8\n",
       " 54\n",
       "  2\n",
       "  2\n",
       " 68\n",
       "  2\n",
       " 58\n",
       " 73\n",
       " 54\n",
       " 54\n",
       " 74\n",
       " 73\n",
       " 61\n",
       "  8\n",
       " 68\n",
       "  2\n",
       "  2\n",
       " 57\n",
       " 66\n",
       " 58\n",
       " 54\n",
       " 27\n",
       " 73\n",
       " 73\n",
       " 78\n",
       " 58\n",
       " 67\n",
       " 73\n",
       " 59\n",
       " 54\n",
       " 62\n",
       " 54\n",
       "  2\n",
       " 56\n",
       " 67\n",
       " 68\n",
       " 56\n",
       " 68\n",
       " 73\n",
       " 58\n",
       " 72\n",
       " 66\n",
       "  2\n",
       " 65\n",
       " 62\n",
       " 58\n",
       " 68\n",
       " 58\n",
       " 69\n",
       " 57\n",
       " 72\n",
       " 58\n",
       "  2\n",
       " 71\n",
       " 58\n",
       "  8\n",
       " 58\n",
       "  4\n",
       " 67\n",
       " 59\n",
       " 67\n",
       " 58\n",
       "  2\n",
       " 72\n",
       " 73\n",
       " 62\n",
       " 68\n",
       " 66\n",
       " 61\n",
       "  2\n",
       " 72\n",
       " 76\n",
       " 58\n",
       " 73\n",
       " 65\n",
       "  2\n",
       " 73\n",
       " 73\n",
       " 58\n",
       " 68\n",
       " 62\n",
       "  2\n",
       " 76\n",
       "  2\n",
       "  2\n",
       " 57\n",
       " 73\n",
       " 67\n",
       " 60\n",
       " 68\n",
       "  2\n",
       " 74\n",
       "  2\n",
       " 73\n",
       "  8\n",
       " 65\n",
       " 69\n",
       " 73\n",
       " 68\n",
       " 58\n",
       " 72\n",
       " 62\n",
       " 73\n",
       " 67\n",
       " 62\n",
       " 67\n",
       " 58\n",
       "  8\n",
       " 67\n",
       " 39\n",
       "  2\n",
       " 62\n",
       " 54\n",
       "  2\n",
       "  2\n",
       " 58\n",
       " 68\n",
       " 66\n",
       " 57\n",
       " 71\n",
       "  2\n",
       "  8\n",
       " 58\n",
       " 65\n",
       "  1\n",
       " 62\n",
       " 73\n",
       "  2\n",
       "  2\n",
       " 55\n",
       " 54\n",
       " 60\n",
       " 72\n",
       " 72\n",
       " 62\n",
       " 56\n",
       " 65\n",
       "  1\n",
       " 58\n",
       " 73\n",
       "  1\n",
       " 58\n",
       " 73\n",
       " 65\n",
       " 67\n",
       " 68\n",
       "  2\n",
       " 54\n",
       " 54\n",
       " 62\n",
       " 67\n",
       " 65\n",
       " 74\n",
       "  2\n",
       " 55\n",
       " 61\n",
       " 72\n",
       " 61\n",
       " 33\n",
       "  2\n",
       " 71\n",
       " 62\n",
       "  1\n",
       " 73\n",
       " 54\n",
       " 66\n",
       "  2\n",
       " 68\n",
       " 58\n",
       " 73\n",
       " 58\n",
       " 71\n",
       "  2\n",
       "  2\n",
       "  2\n",
       " 66\n",
       " 55\n",
       " 69\n",
       " 31\n",
       " 68\n",
       "  1\n",
       " 62\n",
       "  2\n",
       " 54\n",
       " 67\n",
       " 73\n",
       " 61\n",
       " 68\n",
       "  8\n",
       " 73\n",
       "  2\n",
       " 58\n",
       " 67\n",
       " 73\n",
       " 57\n",
       " 54\n",
       " 73\n",
       " 67\n",
       " 58\n",
       " 67\n",
       "  2\n",
       " 58\n",
       "  2\n",
       " 71\n",
       " 58\n",
       " 54\n",
       " 66\n",
       " 62\n",
       " 58\n",
       " 76\n",
       "  2\n",
       " 68\n",
       " 67\n",
       " 61\n",
       " 67\n",
       "  8\n",
       "  2\n",
       "  2\n",
       " 62\n",
       " 71\n",
       "  9\n",
       " 61\n",
       "  2\n",
       " 56\n",
       " 74\n",
       " 72\n",
       " 58\n",
       " 67\n",
       " 62\n",
       " 74\n",
       "  2\n",
       "  2\n",
       " 74\n",
       " 72\n",
       " 67\n",
       " 74\n",
       " 72\n",
       " 58\n",
       " 73\n",
       " 67\n",
       "  2\n",
       " 56\n",
       " 54\n",
       " 58\n",
       " 78\n",
       "  9\n",
       " 61\n",
       " 18\n",
       " 58\n",
       "  2\n",
       " 72\n",
       " 23\n",
       "  2\n",
       " 54\n",
       " 54\n",
       " 76\n",
       " 71\n",
       " 67\n",
       " 54\n",
       " 62\n",
       " 61\n",
       " 51\n",
       " 58\n",
       " 58\n",
       " 29\n",
       " 39\n",
       " 71\n",
       "  2\n",
       "  2\n",
       " 78\n",
       "  2\n",
       " 69\n",
       " 68\n",
       " 68\n",
       "  2\n",
       "  2\n",
       " 57\n",
       "  2\n",
       " 72\n",
       " 57\n",
       " 72\n",
       " 61\n",
       "  2\n",
       " 74\n",
       " 61\n",
       " 60\n",
       " 69\n",
       " 54\n",
       " 62\n",
       " 68\n",
       " 37\n",
       " 60\n",
       " 72\n",
       " 59\n",
       "  2\n",
       " 73\n",
       "  9\n",
       " 69\n",
       " 71\n",
       " 73\n",
       " 68\n",
       " 58\n",
       " 73\n",
       " 59\n",
       " 62\n",
       " 67\n",
       " 56\n",
       " 71\n",
       " 62\n",
       " 60\n",
       " 73\n",
       " 58\n",
       " 68\n",
       "  2\n",
       " 73\n",
       " 67\n",
       " 58\n",
       "  1\n",
       "  2\n",
       " 59\n",
       "  2\n",
       " 58\n",
       " 57\n",
       " 55\n",
       " 68\n",
       " 57\n",
       " 54\n",
       " 73\n",
       " 54\n",
       " 62\n",
       " 61\n",
       " 67\n",
       " 71\n",
       " 71\n",
       "  2\n",
       " 71\n",
       "  2\n",
       " 72\n",
       " 73\n",
       " 30\n",
       " 59\n",
       " 62\n",
       " 57\n",
       "  2\n",
       " 57\n",
       " 69\n",
       " 62\n",
       " 61\n",
       " 73\n",
       " 67\n",
       "  2\n",
       " 71\n",
       " 62\n",
       "  2\n",
       "  2\n",
       " 56\n",
       " 54\n",
       "  8\n",
       " 65\n",
       " 58\n",
       " 71\n",
       " 68\n",
       " 10\n",
       "  9\n",
       " 58\n",
       " 67\n",
       " 69\n",
       " 75\n",
       " 56\n",
       "  2\n",
       " 73\n",
       " 17\n",
       "  2\n",
       " 54\n",
       " 73\n",
       " 65\n",
       " 55\n",
       "  2\n",
       " 67\n",
       " 72\n",
       " 58\n",
       "  2\n",
       " 68\n",
       " 62\n",
       " 74\n",
       " 62\n",
       " 56\n",
       " 74\n",
       " 73\n",
       " 54\n",
       " 54\n",
       " 61\n",
       " 68\n",
       " 61\n",
       " 68\n",
       " 61\n",
       "  1\n",
       " 76\n",
       "  2\n",
       " 65\n",
       " 67\n",
       " 62\n",
       " 73\n",
       " 74\n",
       " 68\n",
       "  2\n",
       " 54\n",
       " 65\n",
       " 72\n",
       " 58\n",
       " 58\n",
       " 67\n",
       " 58\n",
       " 68\n",
       "  1\n",
       "[torch.cuda.LongTensor of size 512 (GPU 0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5eda130cba8415ab843971a320ccbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.977411   1.968401  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.9684])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,1,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ffed03289f4ba994a541d67972828f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.695717   1.696457  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.69646])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,1,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Now we use Pytorch to create the same RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstPytorchRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,n_fac):\n",
    "        super().__init__()\n",
    "        self.e=nn.Embedding(vocab_size,n_fac)\n",
    "        self.rnn=nn.RNN(n_fac,n_hidden)\n",
    "        self.l_out=nn.Linear(n_hidden,vocab_size)\n",
    "        \n",
    "    def forward(self,*cs):\n",
    "        bs=cs[0].size(0)\n",
    "        h=V(torch.zeros(1,bs,n_hidden).cuda())\n",
    "        inp=self.e(torch.stack(cs))\n",
    "        outp,h=self.rnn(inp,h)\n",
    "        return(F.log_softmax(self.l_out(outp[-1]),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=FirstPytorchRNN(vocab_size,n_fac).cuda()\n",
    "opt=optim.Adam(m.parameters(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442b677b5aea469d8364d8298693c514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.881922   1.85588   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.85588])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m,md,1,opt,F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use GRU and LSTM from Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import sgdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "from fastai.text import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai.nlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nietzsche.txt  \u001b[0m\u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls{PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 55, 1, 482908)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT=data.Field(lower=True,tokenize=list)\n",
    "bs=64;bptt=8;n_fac=42\n",
    "\n",
    "FILES=dict(train=TRN_PATH,validation=VAL_PATH,test=VAL_PATH)\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "??repackage_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "??ConcatTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMRnn(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,n_fac,bs,nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e=nn.Embedding(n_hidden,n_fac)\n",
    "        self.rnn=nn.LSTM(n_fac,n_hidden,nl,dropout=0.5)\n",
    "        self.l_out=nn.Linear(n_hidden,vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyLSTMRnn(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325486389d9b4891bf193cfd2b85b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.821988   1.736199  \n",
      "    1      1.713187   1.617606                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.61761])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237dbc2cac6e4955b4fa7b0c29d9356f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.529518   1.472164  \n",
      "    1      1.583065   1.509109                              \n",
      "    2      1.448325   1.418017                              \n",
      "    3      1.612189   1.535976                              \n",
      "    4      1.524319   1.469557                              \n",
      "    5      1.445502   1.407873                              \n",
      "    6      1.377405   1.37387                               \n",
      "    7      1.603567   1.532815                              \n",
      "    8      1.550545   1.497369                              \n",
      "    9      1.518477   1.475922                              \n",
      "    10     1.484052   1.441973                              \n",
      "    11     1.439613   1.407986                              \n",
      "    12     1.382698   1.377323                              \n",
      "    13     1.338167   1.353011                              \n",
      "    14     1.309745   1.339                                 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.339])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1b24e3efb4f758d02b1b154af1ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.294978   1.337187  \n",
      "    1      1.299174   1.334979                              \n",
      "    2      1.295987   1.334602                              \n",
      "    3      1.294428   1.333076                              \n",
      "    4      1.291541   1.330348                              \n",
      "    5      1.286399   1.328944                              \n",
      "    6      1.281721   1.329016                              \n",
      "    7      1.287481   1.327903                              \n",
      "    8      1.279981   1.325342                              \n",
      "    9      1.270692   1.323214                              \n",
      "    10     1.26043    1.321665                              \n",
      "    11     1.257803   1.322192                              \n",
      "    12     1.25446    1.320258                              \n",
      "    13     1.251675   1.320098                              \n",
      "    14     1.2537     1.319983                              \n",
      "    15     1.256717   1.32148                               \n",
      "    16     1.24396    1.319977                              \n",
      "    17     1.24198    1.319187                              \n",
      "    18     1.240794   1.318917                              \n",
      "    19     1.232426   1.317041                              \n",
      "    20     1.223074   1.315955                              \n",
      "    21     1.220633   1.316161                              \n",
      "    22     1.215386   1.315017                              \n",
      "    23     1.210082   1.314796                              \n",
      "    24     1.204952   1.314635                              \n",
      "    25     1.199144   1.31567                               \n",
      "    26     1.195295   1.315186                              \n",
      "    27     1.195485   1.316023                              \n",
      "    28     1.183958   1.316016                              \n",
      "    29     1.190909   1.316333                              \n",
      "    30     1.190658   1.316114                              \n",
      "    31     1.191703   1.316198                              \n",
      "    32     1.203219   1.315807                              \n",
      "    33     1.197253   1.316666                              \n",
      "    34     1.18895    1.316542                              \n",
      "    35     1.183484   1.318056                              \n",
      "    36     1.173287   1.320434                              \n",
      "    37     1.177086   1.320291                              \n",
      "    38     1.168345   1.321565                              \n",
      "    39     1.161076   1.323447                              \n",
      "    40     1.153804   1.323614                              \n",
      "    41     1.151043   1.324531                              \n",
      "    42     1.137711   1.325785                              \n",
      "    43     1.142333   1.328338                              \n",
      "    44     1.126308   1.329401                              \n",
      "    45     1.129567   1.33108                               \n",
      "    46     1.120614   1.333158                              \n",
      "    47     1.119288   1.33785                               \n",
      "    48     1.101754   1.334994                              \n",
      "    49     1.101583   1.339295                              \n",
      "    50     1.102849   1.341313                              \n",
      "    51     1.101698   1.339453                              \n",
      "    52     1.091319   1.340872                              \n",
      "    53     1.086772   1.342404                              \n",
      "    54     1.087054   1.344067                              \n",
      "    55     1.079893   1.344402                              \n",
      "    56     1.085707   1.344838                              \n",
      "    57     1.081944   1.345979                              \n",
      "    58     1.075807   1.34586                               \n",
      "    59     1.081428   1.345772                              \n",
      "    60     1.076907   1.346403                              \n",
      "    61     1.078238   1.346292                              \n",
      "    62     1.075992   1.346658                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.34666])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for those thouthine's home: he his philosopsits which is, as it was only and not-cense with such, asformer effects(the german dicinatelly; not bestow:--it is has longer be handed for theworld of intellectual work in our bad. there are refording for the basis, with my solitude,--we have a discovery, apparently of the part my enammit of the people laugh our brought prevails, men--i, repulstest,[3] gay the s\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to create a dataloader from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=data.Field(sequential=True, tokenize=tokenizer, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
